{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 292,
     "status": "ok",
     "timestamp": 1670796841313,
     "user": {
      "displayName": "Ayush Pandey",
      "userId": "14290991269706383048"
     },
     "user_tz": 300
    },
    "id": "X28hTX5RJ4ke",
    "outputId": "212ed3e6-533d-4e4f-f82f-6baca1d0b9f5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\pande\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\pande\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.stem import PorterStemmer as stemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, Flatten, Conv1D, GlobalMaxPooling1D, MaxPooling1D, Dropout\n",
    "from tensorflow.keras.metrics import Recall, Precision, MeanSquaredError\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, KFold\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, precision_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RTO1Xzj-LMsD"
   },
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1670796843304,
     "user": {
      "displayName": "Ayush Pandey",
      "userId": "14290991269706383048"
     },
     "user_tz": 300
    },
    "id": "QJukRQ_lLI6Y"
   },
   "outputs": [],
   "source": [
    "reviews_labeled = \"data/reviews_labeled.csv\"\n",
    "reviews_scored = \"data/reviews_scored.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 775,
     "status": "ok",
     "timestamp": 1670796844067,
     "user": {
      "displayName": "Ayush Pandey",
      "userId": "14290991269706383048"
     },
     "user_tz": 300
    },
    "id": "oovV_bFRLTNa"
   },
   "outputs": [],
   "source": [
    "dataset1 = pd.read_csv(reviews_labeled)\n",
    "dataset2 = pd.read_csv(reviews_scored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 32,
     "status": "ok",
     "timestamp": 1670796844070,
     "user": {
      "displayName": "Ayush Pandey",
      "userId": "14290991269706383048"
     },
     "user_tz": 300
    },
    "id": "QVRiZ1PdL4PI",
    "outputId": "9af57883-1e6c-4891-df14-a712e9eb5941"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Description</th>\n",
       "      <th>Browser_Used</th>\n",
       "      <th>Device_Used</th>\n",
       "      <th>Is_Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id10326</td>\n",
       "      <td>The room was kind of clean but had a VERY stro...</td>\n",
       "      <td>Edge</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>not happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id10327</td>\n",
       "      <td>I stayed at the Crown Plaza April -- - April -...</td>\n",
       "      <td>Internet Explorer</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>not happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id10328</td>\n",
       "      <td>I booked this hotel through Hotwire at the low...</td>\n",
       "      <td>Mozilla</td>\n",
       "      <td>Tablet</td>\n",
       "      <td>not happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id10329</td>\n",
       "      <td>Stayed here with husband and sons on the way t...</td>\n",
       "      <td>InternetExplorer</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id10330</td>\n",
       "      <td>My girlfriends and I stayed here to celebrate ...</td>\n",
       "      <td>Edge</td>\n",
       "      <td>Tablet</td>\n",
       "      <td>not happy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_ID                                        Description  \\\n",
       "0  id10326  The room was kind of clean but had a VERY stro...   \n",
       "1  id10327  I stayed at the Crown Plaza April -- - April -...   \n",
       "2  id10328  I booked this hotel through Hotwire at the low...   \n",
       "3  id10329  Stayed here with husband and sons on the way t...   \n",
       "4  id10330  My girlfriends and I stayed here to celebrate ...   \n",
       "\n",
       "        Browser_Used Device_Used Is_Response  \n",
       "0               Edge      Mobile   not happy  \n",
       "1  Internet Explorer      Mobile   not happy  \n",
       "2            Mozilla      Tablet   not happy  \n",
       "3   InternetExplorer     Desktop       happy  \n",
       "4               Edge      Tablet   not happy  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1670796844072,
     "user": {
      "displayName": "Ayush Pandey",
      "userId": "14290991269706383048"
     },
     "user_tz": 300
    },
    "id": "7CvCXUgIL7Gp",
    "outputId": "0b65e72d-e817-4f9b-f196-bc104011af3c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nice hotel expensive parking got good deal sta...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ok nothing special charge diamond member hilto...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nice rooms not 4* experience hotel monaco seat...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>unique, great stay, wonderful time hotel monac...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>great stay great stay, went seahawk game aweso...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Rating\n",
       "0  nice hotel expensive parking got good deal sta...       4\n",
       "1  ok nothing special charge diamond member hilto...       2\n",
       "2  nice rooms not 4* experience hotel monaco seat...       3\n",
       "3  unique, great stay, wonderful time hotel monac...       5\n",
       "4  great stay great stay, went seahawk game aweso...       5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3D5x3cIcMFM2"
   },
   "source": [
    "Cleaning Dataset 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 32,
     "status": "ok",
     "timestamp": 1670796844077,
     "user": {
      "displayName": "Ayush Pandey",
      "userId": "14290991269706383048"
     },
     "user_tz": 300
    },
    "id": "8IPm4M9BMG50"
   },
   "outputs": [],
   "source": [
    "# rename columns\n",
    "dataset1 = dataset1.rename({\"Description\": \"text\", \"Is_Response\": \"sentiment\"}, axis=1)[[\"text\", \"sentiment\"]]\n",
    "\n",
    "# replace not happy to 0 and happy to 1\n",
    "dataset1.replace(\"not happy\", 0, inplace=True)\n",
    "dataset1.replace(\"happy\", 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "shVm1IzkMzT7"
   },
   "source": [
    "Cleaning Dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 32,
     "status": "ok",
     "timestamp": 1670796844078,
     "user": {
      "displayName": "Ayush Pandey",
      "userId": "14290991269706383048"
     },
     "user_tz": 300
    },
    "id": "iQwane7EMUbI"
   },
   "outputs": [],
   "source": [
    "# rename columns\n",
    "dataset2 = dataset2.rename({\"Review\": \"text\", \"Rating\": \"sentiment\"}, axis=1)\n",
    "\n",
    "# remove data with sentiment values == 3 since we're only looking at values 1-2 for not happy and 4-5 for happy\n",
    "dataset2 = dataset2[dataset2[\"sentiment\"] != 3]\n",
    "\n",
    "# converting sentiment score to boolean\n",
    "sentiments = [0 if x < 3 else 1 for x in dataset2[\"sentiment\"]]\n",
    "dataset2[\"sentiment\"] = sentiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9EgRo_I6M295"
   },
   "source": [
    "Generating a combined Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 32,
     "status": "ok",
     "timestamp": 1670796844079,
     "user": {
      "displayName": "Ayush Pandey",
      "userId": "14290991269706383048"
     },
     "user_tz": 300
    },
    "id": "N7YLm_h6M1L-"
   },
   "outputs": [],
   "source": [
    "# concatenating datasets\n",
    "dataset = pd.concat([dataset1, dataset2])\n",
    "\n",
    "# removing repeated indexes by resetting the index of the dataframe\n",
    "dataset.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gkydyw1FM_1_"
   },
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 34,
     "status": "ok",
     "timestamp": 1670796844082,
     "user": {
      "displayName": "Ayush Pandey",
      "userId": "14290991269706383048"
     },
     "user_tz": 300
    },
    "id": "BooVnxGPNBX5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# function to remove stopwords + numbers + special characters and convert text to lowercase\n",
    "def preProcess(text):\n",
    "    sents = nltk.sent_tokenize(text)\n",
    "\n",
    "    for i in range(len(sents)):\n",
    "        words = nltk.word_tokenize(sents[i])\n",
    "        for j in range(len(words)):\n",
    "            if words[j] not in set(stopwords.words('english')): \n",
    "                words[j] = re.sub('[^A-Za-z]+','', words[j]) # maybe add numbers\n",
    "                words[j] = words[j].lower()\n",
    "                words[j] = stemmer().stem(words[j])\n",
    "        sents[i] = ' '.join([w for w in words if w != \"\"])\n",
    "    \n",
    "    sents = ' '.join(sents)\n",
    "    return sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "SJ9hr51hNuHs"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 57239/57239 [47:12<00:00, 20.21it/s]  \n"
     ]
    }
   ],
   "source": [
    "texts = list(dataset[\"text\"])\n",
    "for i in tqdm(range(len(texts  ))):\n",
    "    dataset.loc[i, [\"text\"]] = preProcess(texts[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "li9b40FQO2hh"
   },
   "source": [
    "# Support Vector Machines (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f-rHnlAaOyns"
   },
   "source": [
    "TF-IDF Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 5795,
     "status": "ok",
     "timestamp": 1670800837589,
     "user": {
      "displayName": "Ayush Pandey",
      "userId": "14290991269706383048"
     },
     "user_tz": 300
    },
    "id": "Ezqfqqu5OPZG"
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(strip_accents=None, \n",
    "                        lowercase=None, \n",
    "                        preprocessor=None, \n",
    "                        tokenizer=None, \n",
    "                        use_idf=True, \n",
    "                        norm='l2', \n",
    "                        smooth_idf=True)\n",
    "\n",
    "y = dataset.sentiment.values\n",
    "X = vectorizer.fit_transform(dataset.text)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CYU6rEbyPOJx"
   },
   "source": [
    "Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "IXpCFRllPNfU"
   },
   "outputs": [],
   "source": [
    "folds = 5\n",
    "kfold = KFold(n_splits=folds, shuffle=True)\n",
    "\n",
    "scores = []\n",
    "for train, test in kfold.split(X_train, y_train):\n",
    "    model = SVC(kernel='rbf')\n",
    "    model.fit(X_train[train], y_train[train])\n",
    "    \n",
    "    y_pred = model.predict(X_train[test])\n",
    "    s = [recall_score(y_train[test], y_pred), precision_score(y_train[test], y_pred), f1_score(y_train[test], y_pred), accuracy_score(y_train[test], y_pred), mean_squared_error(y_train[test], y_pred)]\n",
    "    scores.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Recall: 0.9574466509461803\n",
      "CV Precision: 0.9240982853537277\n",
      "CV F-measure: 0.940472225019046\n",
      "CV Accuracy: 0.9119259560913869\n",
      "CV MSE: 0.08807404390861302\n"
     ]
    }
   ],
   "source": [
    "print(\"CV Recall:\", np.mean(scores[0]))\n",
    "print(\"CV Precision:\", np.mean(scores[1]))\n",
    "print(\"CV F-measure:\", np.mean(scores[2]))\n",
    "print(\"CV Accuracy:\", np.mean(scores[3]))\n",
    "print(\"CV MSE:\", np.mean(scores[4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xw0qFLF7Pfvj"
   },
   "source": [
    "Fitting the model on X_train & y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "09U5k3HxPbmO"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SVC(kernel='rbf')\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XGKJuChIPl_O"
   },
   "source": [
    "Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "KcMdb9sdPphX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall 0.9565947242206235\n",
      "Precision 0.9250927643784786\n",
      "F-measure 0.940580051874558\n",
      "Accuracy 0.9119496855345912\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Recall\", recall_score(y_test, y_pred))\n",
    "print(\"Precision\", precision_score(y_test, y_pred))\n",
    "print(\"F-measure\", f1_score(y_test, y_pred))\n",
    "print(\"Accuracy\", accuracy_score(y_test, y_pred))\n",
    "print(\"MSE\", mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C0PzSQkIQL07"
   },
   "source": [
    "# Convolutional Neural Networks (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "poWHwHcvQPZp"
   },
   "outputs": [],
   "source": [
    "y = dataset.sentiment.values\n",
    "X = dataset.text.values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HGhuZXjzQ6y3"
   },
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "APKihNKmQ8BU"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "# converting text to sequences\n",
    "sequences_length = 50\n",
    "sequences_train = tokenizer.texts_to_sequences(X_train)\n",
    "sequences_train = pad_sequences(sequences_train, maxlen=sequences_length)\n",
    "\n",
    "sequences_test = tokenizer.texts_to_sequences(X_test)\n",
    "sequences_test = pad_sequences(sequences_test, maxlen=sequences_length)\n",
    "\n",
    "# +1 for OOV words\n",
    "vocabulary_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "iMXpJ4dHRdev"
   },
   "outputs": [],
   "source": [
    "def CNN_Model(seq_len):\n",
    "    embedding_dim = 16\n",
    "    units = 32\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocabulary_size, embedding_dim, input_length=seq_len))\n",
    "    model.add(Conv1D(filters=units, kernel_size=8, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', Recall(), Precision(), MeanSquaredError()])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tznr04KeRM3o"
   },
   "source": [
    "Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "whlozYR2RP8E",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 50, 16)            1106944   \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 43, 32)            4128      \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 21, 32)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 672)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                6730      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,117,813\n",
      "Trainable params: 1,117,813\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/3\n",
      "3664/3664 [==============================] - 37s 9ms/step - loss: 0.3598 - accuracy: 0.8360 - recall: 0.9186 - precision: 0.8644 - mean_squared_error: 0.1146\n",
      "Epoch 2/3\n",
      "3664/3664 [==============================] - 34s 9ms/step - loss: 0.2588 - accuracy: 0.8909 - recall: 0.9360 - precision: 0.9158 - mean_squared_error: 0.0795\n",
      "Epoch 3/3\n",
      "3664/3664 [==============================] - 34s 9ms/step - loss: 0.1824 - accuracy: 0.9266 - recall: 0.9562 - precision: 0.9437 - mean_squared_error: 0.0545\n",
      "287/287 [==============================] - 1s 1ms/step - loss: 0.4170 - accuracy: 0.8497 - recall: 0.9339 - precision: 0.8682 - mean_squared_error: 0.1152\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 50, 16)            1106944   \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 43, 32)            4128      \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 21, 32)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 672)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                6730      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,117,813\n",
      "Trainable params: 1,117,813\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/3\n",
      "3664/3664 [==============================] - 34s 9ms/step - loss: 0.3580 - accuracy: 0.8358 - recall_1: 0.9187 - precision_1: 0.8641 - mean_squared_error: 0.1140\n",
      "Epoch 2/3\n",
      "3664/3664 [==============================] - 34s 9ms/step - loss: 0.2526 - accuracy: 0.8954 - recall_1: 0.9403 - precision_1: 0.9179 - mean_squared_error: 0.0772\n",
      "Epoch 3/3\n",
      "3664/3664 [==============================] - 34s 9ms/step - loss: 0.1758 - accuracy: 0.9314 - recall_1: 0.9594 - precision_1: 0.9470 - mean_squared_error: 0.0519\n",
      "287/287 [==============================] - 1s 1ms/step - loss: 0.3821 - accuracy: 0.8490 - recall_1: 0.9228 - precision_1: 0.8754 - mean_squared_error: 0.1128\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 50, 16)            1106944   \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 43, 32)            4128      \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 21, 32)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 672)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 10)                6730      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,117,813\n",
      "Trainable params: 1,117,813\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/3\n",
      "3664/3664 [==============================] - 35s 9ms/step - loss: 0.3604 - accuracy: 0.8347 - recall_2: 0.9184 - precision_2: 0.8624 - mean_squared_error: 0.1148\n",
      "Epoch 2/3\n",
      "3664/3664 [==============================] - 34s 9ms/step - loss: 0.2566 - accuracy: 0.8916 - recall_2: 0.9367 - precision_2: 0.9155 - mean_squared_error: 0.0786\n",
      "Epoch 3/3\n",
      "3664/3664 [==============================] - 35s 9ms/step - loss: 0.1763 - accuracy: 0.9303 - recall_2: 0.9585 - precision_2: 0.9460 - mean_squared_error: 0.0522\n",
      "287/287 [==============================] - 1s 1ms/step - loss: 0.3685 - accuracy: 0.8532 - recall_2: 0.9258 - precision_2: 0.8808 - mean_squared_error: 0.1079\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, 50, 16)            1106944   \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 43, 32)            4128      \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPooling  (None, 21, 32)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 672)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 10)                6730      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,117,813\n",
      "Trainable params: 1,117,813\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/3\n",
      "3664/3664 [==============================] - 35s 9ms/step - loss: 0.3595 - accuracy: 0.8371 - recall_3: 0.9167 - precision_3: 0.8667 - mean_squared_error: 0.1145\n",
      "Epoch 2/3\n",
      "3664/3664 [==============================] - 34s 9ms/step - loss: 0.2472 - accuracy: 0.8979 - recall_3: 0.9381 - precision_3: 0.9227 - mean_squared_error: 0.0754\n",
      "Epoch 3/3\n",
      "3664/3664 [==============================] - 34s 9ms/step - loss: 0.1621 - accuracy: 0.9357 - recall_3: 0.9587 - precision_3: 0.9531 - mean_squared_error: 0.0478\n",
      "287/287 [==============================] - 1s 1ms/step - loss: 0.4177 - accuracy: 0.8488 - recall_3: 0.9251 - precision_3: 0.8740 - mean_squared_error: 0.1134\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, 50, 16)            1106944   \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 43, 32)            4128      \n",
      "                                                                 \n",
      " max_pooling1d_4 (MaxPooling  (None, 21, 32)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 672)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 10)                6730      \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,117,813\n",
      "Trainable params: 1,117,813\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/3\n",
      "3664/3664 [==============================] - 35s 9ms/step - loss: 0.3616 - accuracy: 0.8353 - recall_4: 0.9234 - precision_4: 0.8605 - mean_squared_error: 0.1150\n",
      "Epoch 2/3\n",
      "3664/3664 [==============================] - 34s 9ms/step - loss: 0.2564 - accuracy: 0.8921 - recall_4: 0.9377 - precision_4: 0.9160 - mean_squared_error: 0.0782\n",
      "Epoch 3/3\n",
      "3664/3664 [==============================] - 34s 9ms/step - loss: 0.1743 - accuracy: 0.9304 - recall_4: 0.9588 - precision_4: 0.9463 - mean_squared_error: 0.0515\n",
      "287/287 [==============================] - 1s 2ms/step - loss: 0.4183 - accuracy: 0.8421 - recall_4: 0.9356 - precision_4: 0.8589 - mean_squared_error: 0.1196\n"
     ]
    }
   ],
   "source": [
    "folds = 5\n",
    "kfold = KFold(n_splits=folds, shuffle=True)\n",
    "\n",
    "scores = []\n",
    "for train, test in kfold.split(sequences_train, y_train):\n",
    "    model = CNN_Model(sequences_length)\n",
    "    model.summary()\n",
    "    \n",
    "    model.fit(sequences_train[train], y_train[train], epochs = 3, batch_size=10, verbose = 1)\n",
    "    \n",
    "    s = model.evaluate(sequences_train[test], y_train[test], verbose=1)\n",
    "    scores.append(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KAO7eeFdVBWz"
   },
   "source": [
    "CV Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "whk1BrpnRvWh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.4007066547870636\n",
      "accuracy: 0.8485509991645813\n",
      "recall_4: 0.9286358594894409\n",
      "precision_4: 0.871467399597168\n",
      "mean_squared_error: 0.11377326995134354\n"
     ]
    }
   ],
   "source": [
    "for j, name in enumerate(model.metrics_names):\n",
    "    print(f\"{name}:\", np.mean([score[model.metrics_names.index(name)] for score in scores]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2e2SRpxbVEVh"
   },
   "source": [
    "Test Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "8nBwnzB5VDUN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "4580/4580 [==============================] - 43s 9ms/step - loss: 0.3551 - accuracy: 0.8376 - recall_5: 0.9230 - precision_5: 0.8630 - mean_squared_error: 0.1128\n",
      "Epoch 2/3\n",
      "4580/4580 [==============================] - 43s 9ms/step - loss: 0.2573 - accuracy: 0.8905 - recall_5: 0.9363 - precision_5: 0.9149 - mean_squared_error: 0.0789\n",
      "Epoch 3/3\n",
      "4580/4580 [==============================] - 43s 9ms/step - loss: 0.1862 - accuracy: 0.9249 - recall_5: 0.9560 - precision_5: 0.9416 - mean_squared_error: 0.0553\n",
      "358/358 [==============================] - 1s 1ms/step - loss: 0.4017 - accuracy: 0.8525 - recall_5: 0.9271 - precision_5: 0.8773 - mean_squared_error: 0.1114\n"
     ]
    }
   ],
   "source": [
    "model = CNN_Model(sequences_length)\n",
    "model.fit(sequences_train, y_train, epochs=3, batch_size=10, verbose=1)\n",
    "metrics = model.evaluate(sequences_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eL0iwjyRTvjd"
   },
   "source": [
    "# Long Short Term Memory (LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "C5Yp3Y-6Ty5e"
   },
   "outputs": [],
   "source": [
    "def LSTM_Model():\n",
    "    embedding_dim = 16\n",
    "    lstm_units = 32\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocabulary_size, embedding_dim))\n",
    "    model.add(LSTM(lstm_units))\n",
    "    model.add(Dropout(.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', Precision(), Recall(), MeanSquaredError()])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qKBCYHZnVSt2"
   },
   "source": [
    "Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "bfA0u3vjUodn",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_6 (Embedding)     (None, None, 16)          1106944   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 32)                6272      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,113,249\n",
      "Trainable params: 1,113,249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/3\n",
      "3664/3664 [==============================] - 71s 19ms/step - loss: 0.3737 - accuracy: 0.8369 - precision_6: 0.8665 - recall_6: 0.9172 - mean_squared_error: 0.1177\n",
      "Epoch 2/3\n",
      "3664/3664 [==============================] - 68s 19ms/step - loss: 0.2846 - accuracy: 0.8804 - precision_6: 0.9088 - recall_6: 0.9289 - mean_squared_error: 0.0864\n",
      "Epoch 3/3\n",
      "3664/3664 [==============================] - 68s 19ms/step - loss: 0.2442 - accuracy: 0.8997 - precision_6: 0.9227 - recall_6: 0.9410 - mean_squared_error: 0.0735\n",
      "287/287 [==============================] - 2s 4ms/step - loss: 0.3407 - accuracy: 0.8552 - precision_6: 0.8875 - recall_6: 0.9154 - mean_squared_error: 0.1051\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_7 (Embedding)     (None, None, 16)          1106944   \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 32)                6272      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,113,249\n",
      "Trainable params: 1,113,249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/3\n",
      "3664/3664 [==============================] - 71s 19ms/step - loss: 0.3728 - accuracy: 0.8376 - precision_7: 0.8719 - recall_7: 0.9098 - mean_squared_error: 0.1171\n",
      "Epoch 2/3\n",
      "3664/3664 [==============================] - 69s 19ms/step - loss: 0.2868 - accuracy: 0.8809 - precision_7: 0.9092 - recall_7: 0.9285 - mean_squared_error: 0.0874\n",
      "Epoch 3/3\n",
      "3664/3664 [==============================] - 68s 19ms/step - loss: 0.2430 - accuracy: 0.8991 - precision_7: 0.9224 - recall_7: 0.9399 - mean_squared_error: 0.0733\n",
      "287/287 [==============================] - 2s 4ms/step - loss: 0.3262 - accuracy: 0.8585 - precision_7: 0.8880 - recall_7: 0.9230 - mean_squared_error: 0.1011\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_8 (Embedding)     (None, None, 16)          1106944   \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 32)                6272      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,113,249\n",
      "Trainable params: 1,113,249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/3\n",
      "3664/3664 [==============================] - 70s 19ms/step - loss: 0.3702 - accuracy: 0.8360 - precision_8: 0.8707 - recall_8: 0.9096 - mean_squared_error: 0.1167\n",
      "Epoch 2/3\n",
      "3664/3664 [==============================] - 68s 19ms/step - loss: 0.2828 - accuracy: 0.8808 - precision_8: 0.9104 - recall_8: 0.9274 - mean_squared_error: 0.0863\n",
      "Epoch 3/3\n",
      "3664/3664 [==============================] - 68s 19ms/step - loss: 0.2420 - accuracy: 0.8997 - precision_8: 0.9237 - recall_8: 0.9397 - mean_squared_error: 0.0730\n",
      "287/287 [==============================] - 2s 4ms/step - loss: 0.3552 - accuracy: 0.8579 - precision_8: 0.8912 - recall_8: 0.9156 - mean_squared_error: 0.1050\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_9 (Embedding)     (None, None, 16)          1106944   \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 32)                6272      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,113,249\n",
      "Trainable params: 1,113,249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/3\n",
      "3664/3664 [==============================] - 70s 18ms/step - loss: 0.3718 - accuracy: 0.8350 - precision_9: 0.8697 - recall_9: 0.9094 - mean_squared_error: 0.1169\n",
      "Epoch 2/3\n",
      "3664/3664 [==============================] - 68s 19ms/step - loss: 0.2825 - accuracy: 0.8805 - precision_9: 0.9088 - recall_9: 0.9289 - mean_squared_error: 0.0862\n",
      "Epoch 3/3\n",
      "3664/3664 [==============================] - 68s 19ms/step - loss: 0.2404 - accuracy: 0.9013 - precision_9: 0.9235 - recall_9: 0.9423 - mean_squared_error: 0.0722\n",
      "287/287 [==============================] - 2s 4ms/step - loss: 0.3874 - accuracy: 0.8572 - precision_9: 0.8749 - recall_9: 0.9369 - mean_squared_error: 0.1087\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_10 (Embedding)    (None, None, 16)          1106944   \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 32)                6272      \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,113,249\n",
      "Trainable params: 1,113,249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/3\n",
      "3664/3664 [==============================] - 71s 19ms/step - loss: 0.3731 - accuracy: 0.8367 - precision_10: 0.8720 - recall_10: 0.9082 - mean_squared_error: 0.1173\n",
      "Epoch 2/3\n",
      "3664/3664 [==============================] - 68s 19ms/step - loss: 0.2847 - accuracy: 0.8813 - precision_10: 0.9092 - recall_10: 0.9292 - mean_squared_error: 0.0868\n",
      "Epoch 3/3\n",
      "3664/3664 [==============================] - 68s 19ms/step - loss: 0.2405 - accuracy: 0.9004 - precision_10: 0.9244 - recall_10: 0.9395 - mean_squared_error: 0.0724\n",
      "287/287 [==============================] - 2s 4ms/step - loss: 0.3320 - accuracy: 0.8566 - precision_10: 0.9010 - recall_10: 0.9032 - mean_squared_error: 0.1028\n"
     ]
    }
   ],
   "source": [
    "folds = 5\n",
    "kfold = KFold(n_splits=folds, shuffle=True)\n",
    "\n",
    "scores = []\n",
    "for train, test in kfold.split(sequences_train, y_train):\n",
    "    model = LSTM_Model()\n",
    "    model.summary()\n",
    "    \n",
    "    model.fit(sequences_train[train], y_train[train], epochs = 3, batch_size=10, verbose = 1)\n",
    "    \n",
    "    s = model.evaluate(sequences_train[test], y_train[test], verbose=1)\n",
    "    \n",
    "    scores.append(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tNx8MxpFVXG8"
   },
   "source": [
    "CV Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "dg_n7ArZU7ai",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.34831780195236206\n",
      "accuracy: 0.8570898532867431\n",
      "precision_10: 0.8885136604309082\n",
      "recall_10: 0.9188119173049927\n",
      "mean_squared_error: 0.10452398061752319\n"
     ]
    }
   ],
   "source": [
    "for j, name in enumerate(model.metrics_names):\n",
    "    print(f\"{name}:\", np.mean([score[model.metrics_names.index(name)] for score in scores]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cr-11TUvVZJv",
    "tags": []
   },
   "source": [
    "Test Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "LMAfghGeVZtq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "4580/4580 [==============================] - 87s 19ms/step - loss: 0.3634 - accuracy: 0.8409 - precision_11: 0.8740 - recall_11: 0.9126 - mean_squared_error: 0.1139\n",
      "Epoch 2/3\n",
      "4580/4580 [==============================] - 86s 19ms/step - loss: 0.2833 - accuracy: 0.8808 - precision_11: 0.9079 - recall_11: 0.9304 - mean_squared_error: 0.0866\n",
      "Epoch 3/3\n",
      "4580/4580 [==============================] - 86s 19ms/step - loss: 0.2436 - accuracy: 0.8983 - precision_11: 0.9206 - recall_11: 0.9412 - mean_squared_error: 0.0738\n",
      "358/358 [==============================] - 3s 5ms/step - loss: 0.3438 - accuracy: 0.8590 - precision_11: 0.8793 - recall_11: 0.9348 - mean_squared_error: 0.1030\n"
     ]
    }
   ],
   "source": [
    "model = LSTM_Model()\n",
    "model.fit(sequences_train, y_train, epochs=3, batch_size=10, verbose=1)\n",
    "metrics = model.evaluate(sequences_test, y_test, verbose=1)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPcWUZX/6r5l/INnP3/MmsX",
   "mount_file_id": "1gf7EJKyK9pjCiK-rm6FnIdteE-hdVy1s",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
